{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0080acd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal, TypedDict\n",
    "from langgraph.graph import END\n",
    "from langgraph.graph.state import StateGraph\n",
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
    "from langchain.chat_models import init_chat_model\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from langgraph.graph.message import add_messages\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9705f8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7505f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x128f02110>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x128f031d0>, model_name='gemma2-9b-it', temperature=1e-08, model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = init_chat_model(\"groq:gemma2-9b-it\", temperature=0)\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ab52414",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrgState(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "    next_agent: Literal[\"ceo\",\"research_lead\",\"data_researcher\",\"market_researcher\",\"writing_lead\",\"tech_writer\",\"summary_writer\",\"end\"] | None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9cc52b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ceo(state: OrgState) -> dict:\n",
    "    \"\"\"CEO coordinates team leaders; deterministic progression prevents loops.\"\"\"\n",
    "    msgs = state.get(\"messages\", [])\n",
    "    task = msgs[-1].content if msgs else state.get(\"current_task\", \"\")\n",
    "\n",
    "    # Decide stage by stage\n",
    "    if not state.get(\"research_synthesized\", False):\n",
    "        msg = \"CEO: Handing off to Research Team Leader for research.\"  # -> research_lead\n",
    "        nxt = \"research_lead\"\n",
    "    elif not (state.get(\"tech_draft_done\", False) and state.get(\"summary_done\", False)):\n",
    "        msg = \"CEO: Handing off to Writing Team Leader for drafting & summary.\"  # -> writing_lead\n",
    "        nxt = \"writing_lead\"\n",
    "    else:\n",
    "        # Assemble final report once both drafts present\n",
    "        final = (\n",
    "            \"FINAL REPORT\\n\" + \"=\" * 60 + \"\\n\" +\n",
    "            f\"Generated: {datetime.now().isoformat()}\\n\" +\n",
    "            f\"Topic: {task}\\n\" + \"=\" * 60 + \"\\n\\n\" +\n",
    "            \"Research Synthesis:\\n\" + state.get(\"research_synthesis\", \"\") + \"\\n\\n\" +\n",
    "            \"Technical Draft:\\n\" + state.get(\"tech_draft\", \"\") + \"\\n\\n\" +\n",
    "            \"Executive Summary:\\n\" + state.get(\"summary_text\", \"\") + \"\\n\"\n",
    "        )\n",
    "        return {\n",
    "            \"messages\": [AIMessage(content=\"CEO: Collected all artifacts. Finalizing report.\")],\n",
    "            \"final_report\": final,\n",
    "            \"task_complete\": True,\n",
    "            \"next_agent\": \"end\",\n",
    "            \"current_task\": task,\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=msg)],\n",
    "        \"next_agent\": nxt,\n",
    "        \"current_task\": task,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2336c320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_lead(state: OrgState) -> dict:\n",
    "    \"\"\"Orchestrates Data & Market researchers, then synthesizes findings.\"\"\"\n",
    "    task = state.get(\"current_task\", \"\")\n",
    "    data_done = state.get(\"data_done\", False)\n",
    "    market_done = state.get(\"market_done\", False)\n",
    "\n",
    "    if not data_done:\n",
    "        return {\n",
    "            \"messages\": [AIMessage(content=\"Research Lead: Sending to Data Researcher.\")],\n",
    "            \"next_agent\": \"data_researcher\",\n",
    "            \"current_task\": task,\n",
    "        }\n",
    "    if not market_done:\n",
    "        return {\n",
    "            \"messages\": [AIMessage(content=\"Research Lead: Sending to Market Researcher.\")],\n",
    "            \"next_agent\": \"market_researcher\",\n",
    "            \"current_task\": task,\n",
    "        }\n",
    "\n",
    "    # Both complete -> synthesize once\n",
    "    if not state.get(\"research_synthesized\", False):\n",
    "        synthesis_prompt = (\n",
    "            \"You are a Research Team Leader. Synthesize the two briefs into a concise,\\n\"\n",
    "            \"actionable research summary with citations and contradictions called out.\\n\\n\"\n",
    "            f\"Task: {task}\\n\\n\"\n",
    "            f\"DATA NOTES:\\n{state.get('data_notes','')}\\n\\n\"\n",
    "            f\"MARKET NOTES:\\n{state.get('market_notes','')}\\n\"\n",
    "        )\n",
    "        out = llm.invoke([HumanMessage(content=synthesis_prompt)]).content\n",
    "        return {\n",
    "            \"messages\": [AIMessage(content=\"Research Lead: Synthesis completed.\")],\n",
    "            \"research_synthesis\": out,\n",
    "            \"research_synthesized\": True,\n",
    "            \"next_agent\": \"ceo\",\n",
    "        }\n",
    "\n",
    "    # Already synthesized -> return to CEO\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=\"Research Lead: Research package ready. Returning to CEO.\")],\n",
    "        \"next_agent\": \"ceo\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e3e95f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_researcher(state: OrgState) -> dict:\n",
    "    task = state.get(\"current_task\", \"\")\n",
    "    prompt = (\n",
    "        \"You are a Data Researcher. Provide data-driven facts: stats, studies,\\n\"\n",
    "        \"benchmarks, methodologies. Cite inline. Keep it tight (200-300 words).\\n\\n\"\n",
    "        f\"Topic: {task}\"\n",
    "    )\n",
    "    out = llm.invoke([HumanMessage(content=prompt)]).content\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=\"Data Researcher: Provided data brief.\")],\n",
    "        \"data_notes\": out,\n",
    "        \"data_done\": True,\n",
    "        \"next_agent\": \"research_lead\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43a4e602",
   "metadata": {},
   "outputs": [],
   "source": [
    "def market_researcher(state: OrgState) -> dict:\n",
    "    task = state.get(\"current_task\", \"\")\n",
    "    prompt = (\n",
    "        \"You are a Market Researcher. Provide market landscape: segments, TAM/SAM,\\n\"\n",
    "        \"competitors, pricing, trends, regulatory factors. Cite inline. 200-300 words.\\n\\n\"\n",
    "        f\"Topic: {task}\"\n",
    "    )\n",
    "    out = llm.invoke([HumanMessage(content=prompt)]).content\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=\"Market Researcher: Provided market brief.\")],\n",
    "        \"market_notes\": out,\n",
    "        \"market_done\": True,\n",
    "        \"next_agent\": \"research_lead\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "766f5277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writing_lead(state: OrgState) -> dict:\n",
    "    task = state.get(\"current_task\", \"\")\n",
    "    if not state.get(\"tech_draft_done\", False):\n",
    "        return {\n",
    "            \"messages\": [AIMessage(content=\"Writing Lead: Sending to Technical Writer.\")],\n",
    "            \"next_agent\": \"tech_writer\",\n",
    "            \"current_task\": task,\n",
    "        }\n",
    "    if not state.get(\"summary_done\", False):\n",
    "        return {\n",
    "            \"messages\": [AIMessage(content=\"Writing Lead: Sending to Summary Writer.\")],\n",
    "            \"next_agent\": \"summary_writer\",\n",
    "            \"current_task\": task,\n",
    "        }\n",
    "\n",
    "    # Both present -> return to CEO for finalization\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=\"Writing Lead: Draft & summary ready. Returning to CEO.\")],\n",
    "        \"next_agent\": \"ceo\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5615bbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tech_writer(state: OrgState) -> dict:\n",
    "    task = state.get(\"current_task\", \"\")\n",
    "    prompt = (\n",
    "        \"You are a Technical Writer. Convert the research synthesis into a structured,\\n\"\n",
    "        \"well-cited technical write-up with headings and bullet points where useful.\\n\"\n",
    "        \"Audience: domain practitioners. 300-400 words.\\n\\n\"\n",
    "        f\"Task: {task}\\n\\n\"\n",
    "        f\"Research Synthesis:\\n{state.get('research_synthesis','')}\\n\"\n",
    "    )\n",
    "    out = llm.invoke([HumanMessage(content=prompt)]).content\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=\"Technical Writer: Produced technical draft.\")],\n",
    "        \"tech_draft\": out,\n",
    "        \"tech_draft_done\": True,\n",
    "        \"next_agent\": \"writing_lead\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d5cd730",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_writer(state: OrgState) -> dict:\n",
    "    task = state.get(\"current_task\", \"\")\n",
    "    prompt = (\n",
    "        \"You are a Summary Writer. Produce an executive summary (120-180 words)\\n\"\n",
    "        \"for senior leadership. Focus on ROI, risk, timeline. Include 3 bullets\\n\"\n",
    "        \"with clear recommendations.\\n\\n\"\n",
    "        f\"Task: {task}\\n\\n\"\n",
    "        f\"Research Synthesis:\\n{state.get('research_synthesis','')}\\n\"\n",
    "    )\n",
    "    out = llm.invoke([HumanMessage(content=prompt)]).content\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=\"Summary Writer: Produced executive summary.\" )],\n",
    "        \"summary_text\": out,\n",
    "        \"summary_done\": True,\n",
    "        \"next_agent\": \"writing_lead\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38df7de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import get_args\n",
    "\n",
    "def router(state: OrgState) -> Literal[\n",
    "    \"ceo\",\n",
    "    \"research_lead\",\n",
    "    \"data_researcher\",\n",
    "    \"market_researcher\",\n",
    "    \"writing_lead\",\n",
    "    \"tech_writer\",\n",
    "    \"summary_writer\",\n",
    "    END,\n",
    "]:\n",
    "    nxt = state.get(\"next_agent\") or \"ceo\"\n",
    "    if nxt == \"end\" or state.get(\"task_complete\", False):\n",
    "        return END\n",
    "    allowed = {\n",
    "        \"ceo\",\n",
    "        \"research_lead\",\n",
    "        \"data_researcher\",\n",
    "        \"market_researcher\",\n",
    "        \"writing_lead\",\n",
    "        \"tech_writer\",\n",
    "        \"summary_writer\",\n",
    "    }\n",
    "    return nxt if nxt in allowed else \"ceo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d654f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(OrgState)\n",
    "\n",
    "workflow.add_node(\"ceo\", ceo)\n",
    "workflow.add_node(\"research_lead\", research_lead)\n",
    "workflow.add_node(\"data_researcher\", data_researcher)\n",
    "workflow.add_node(\"market_researcher\", market_researcher)\n",
    "workflow.add_node(\"writing_lead\", writing_lead)\n",
    "workflow.add_node(\"tech_writer\", tech_writer)\n",
    "workflow.add_node(\"summary_writer\", summary_writer)\n",
    "\n",
    "workflow.set_entry_point(\"ceo\")\n",
    "\n",
    "for node in [\n",
    "    \"ceo\",\n",
    "    \"research_lead\",\n",
    "    \"data_researcher\",\n",
    "    \"market_researcher\",\n",
    "    \"writing_lead\",\n",
    "    \"tech_writer\",\n",
    "    \"summary_writer\",\n",
    "]:\n",
    "    workflow.add_conditional_edges(\n",
    "        node,\n",
    "        router,\n",
    "        {\n",
    "            \"ceo\": \"ceo\",\n",
    "            \"research_lead\": \"research_lead\",\n",
    "            \"data_researcher\": \"data_researcher\",\n",
    "            \"market_researcher\": \"market_researcher\",\n",
    "            \"writing_lead\": \"writing_lead\",\n",
    "            \"tech_writer\": \"tech_writer\",\n",
    "            \"summary_writer\": \"summary_writer\",\n",
    "            END: END,\n",
    "        },\n",
    "    )\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "702c77ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/langsmith/client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=e5f8fd85-0b47-447d-83f8-f50561f77f20; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=67281e1b-24a5-42e0-a12f-caceed8b8da3; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=f7146b6f-dde4-4798-a15d-9251f4490de1; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=eb502c30-7b77-4d01-830d-9c0ee79cdd1f; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=55d5f6e3-e28b-466d-81d0-c6c4ad4ffbe8; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=aa1503b7-9805-4a29-826e-9230458eb25f\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=aa1503b7-9805-4a29-826e-9230458eb25f; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=130b99b4-2428-4498-9c25-3f099c651923; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=130b99b4-2428-4498-9c25-3f099c651923; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=55d5f6e3-e28b-466d-81d0-c6c4ad4ffbe8; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=6c388221-2241-4ae1-b832-d3885276d108; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=12e32cf9-7155-43d3-9ba4-50e2b2526d20; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=12e32cf9-7155-43d3-9ba4-50e2b2526d20; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=6c388221-2241-4ae1-b832-d3885276d108; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=df90ec38-6f69-48d3-ad1b-84af0f3e1223; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=bd9a2936-d1ca-4306-a48b-785c988d50f5; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=bd9a2936-d1ca-4306-a48b-785c988d50f5; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=c49ef5e6-358a-4eab-ad15-cb8d4f812eef; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=c49ef5e6-358a-4eab-ad15-cb8d4f812eef; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=df90ec38-6f69-48d3-ad1b-84af0f3e1223; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=ce514faf-e3de-418e-bbb3-dfc0ad013dc1; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=3af66c68-7415-4ecf-8ca3-e1c23f59f3db; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=3af66c68-7415-4ecf-8ca3-e1c23f59f3db; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=ce514faf-e3de-418e-bbb3-dfc0ad013dc1; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=33136de5-7427-4a0a-bc62-6bc5e33943db; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=98d0280f-5dad-4958-b2d5-a7be1e85c77c\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=98d0280f-5dad-4958-b2d5-a7be1e85c77c; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=c3c29c57-7233-4c1c-aa8e-6016ad042bbf; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=c3c29c57-7233-4c1c-aa8e-6016ad042bbf; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=33136de5-7427-4a0a-bc62-6bc5e33943db; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=6f359052-c386-4a3b-bab3-8b8110228375; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=4dd89579-1a2e-415e-88a4-eba41496569d; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=4dd89579-1a2e-415e-88a4-eba41496569d; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=6f359052-c386-4a3b-bab3-8b8110228375; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=1bbb5ec4-5636-47ad-8759-5ff86fc5a205; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=095bc89e-bf63-4512-bea2-3cf7980059a2; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=095bc89e-bf63-4512-bea2-3cf7980059a2; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=2e197a04-3edc-48cc-92ce-d175209637e4; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=2e197a04-3edc-48cc-92ce-d175209637e4; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=1bbb5ec4-5636-47ad-8759-5ff86fc5a205; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=7d6c0577-eb09-4524-8114-528e4143fce7; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=35a640ca-1466-44e1-aa34-c6ede01c3c69; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=35a640ca-1466-44e1-aa34-c6ede01c3c69; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=7d6c0577-eb09-4524-8114-528e4143fce7; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=ffc81649-6e88-43f4-baf4-b63479f3218a; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=9308a6e6-bbc7-4a18-a88d-4be2f14481bb; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=9308a6e6-bbc7-4a18-a88d-4be2f14481bb; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=cc52cd7c-fc91-4f0a-841b-1eb08b8fe370; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=cc52cd7c-fc91-4f0a-841b-1eb08b8fe370; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=ffc81649-6e88-43f4-baf4-b63479f3218a; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=d768d636-b557-41e2-8493-2316373ae061; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=1bbbc8c5-338a-44bd-ad95-58139e653bd2; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=1bbbc8c5-338a-44bd-ad95-58139e653bd2; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=d768d636-b557-41e2-8493-2316373ae061; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=a0e90e4a-9182-430e-b378-786d07c8e239; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=e0edd0aa-cee6-4a9d-91e6-88fd6d7ea174; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=e0edd0aa-cee6-4a9d-91e6-88fd6d7ea174; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=e56b91bf-ea79-4af4-8cf4-cf5ef8a8ce68; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=e56b91bf-ea79-4af4-8cf4-cf5ef8a8ce68; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=a0e90e4a-9182-430e-b378-786d07c8e239; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=2e329d69-79e2-478e-9a1b-5f418dbe9092; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=1e7c97bc-e8b4-43ce-9487-0f1d0d523752; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=1e7c97bc-e8b4-43ce-9487-0f1d0d523752; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=2e329d69-79e2-478e-9a1b-5f418dbe9092; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=07c32396-493d-4ecf-926d-32fd65dc0044; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=65d3308c-0054-4dc5-bc77-dfaea8bc560d; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=65d3308c-0054-4dc5-bc77-dfaea8bc560d; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=80848c9a-8e6d-489a-b3df-bd6060b199ef; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=80848c9a-8e6d-489a-b3df-bd6060b199ef; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=07c32396-493d-4ecf-926d-32fd65dc0044; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=7eb8ff24-e6ac-4ed1-8507-a372ac05f321; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=2cd84d72-840e-42b0-a209-374f4ca29fc3; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=2cd84d72-840e-42b0-a209-374f4ca29fc3; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=7eb8ff24-e6ac-4ed1-8507-a372ac05f321; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=af4aea61-7ac3-464a-a55d-00ecd68f6ce7; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=c62153a0-3336-4482-aedb-52c4ae9da714\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=c62153a0-3336-4482-aedb-52c4ae9da714; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=da906286-be9c-4faa-9e4e-f8dcb4810d26; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=da906286-be9c-4faa-9e4e-f8dcb4810d26; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=af4aea61-7ac3-464a-a55d-00ecd68f6ce7; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=477700ce-c898-4063-909e-11711e1225b5; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=f9d7266e-4656-4aff-affa-db24220c4186; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=f9d7266e-4656-4aff-affa-db24220c4186; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=477700ce-c898-4063-909e-11711e1225b5; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=4807533c-4c87-4823-bfd7-e85673119ba8; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=a54584bd-7b50-429f-baf8-440ab67b82e0; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=a54584bd-7b50-429f-baf8-440ab67b82e0; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=8292b567-8d95-4c5b-8b69-1598d8cbb4d4; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=8292b567-8d95-4c5b-8b69-1598d8cbb4d4; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=4807533c-4c87-4823-bfd7-e85673119ba8; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=c6b0df06-6741-4b72-8b4a-67febc7999b9; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=f0783d4b-c219-4afc-bbfb-ac99367d564e; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=f0783d4b-c219-4afc-bbfb-ac99367d564e; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=c6b0df06-6741-4b72-8b4a-67febc7999b9; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=2e7d212a-ee08-4914-877a-313488144366; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=c7c3c561-76d5-44c8-8c18-29f9b5008356\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=c7c3c561-76d5-44c8-8c18-29f9b5008356; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=6cfe4560-e85a-4fd8-8dd8-8246297e1abd; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=6cfe4560-e85a-4fd8-8dd8-8246297e1abd; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=2e7d212a-ee08-4914-877a-313488144366; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=f2cff064-74c3-402e-8c4f-605e6b122f16; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=63848bc6-aff9-4e2d-b315-9c11c254df11; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=63848bc6-aff9-4e2d-b315-9c11c254df11; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=f2cff064-74c3-402e-8c4f-605e6b122f16; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=e98adf24-5551-4a2e-9058-08371c6a8127; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=37960851-a501-4637-8d3d-7df7b26fa965\n"
     ]
    },
    {
     "ename": "GraphRecursionError",
     "evalue": "Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mGraphRecursionError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m      2\u001b[39m     init_state: OrgState = {\n\u001b[32m      3\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m      4\u001b[39m             HumanMessage(content=(\n\u001b[32m   (...)\u001b[39m\u001b[32m     22\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtask_complete\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     23\u001b[39m     }\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     result = \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- PIPELINE COMPLETE ---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     28\u001b[39m     \u001b[38;5;28mprint\u001b[39m((result.get(\u001b[33m\"\u001b[39m\u001b[33mfinal_report\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m<no final report>\u001b[39m\u001b[33m\"\u001b[39m)[:\u001b[32m2000\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.11/site-packages/langgraph/pregel/main.py:3026\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3023\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3024\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3026\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3027\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3028\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3029\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3030\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3031\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3032\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3033\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3034\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3035\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3036\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3037\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3038\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3039\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3040\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3041\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.11/site-packages/langgraph/pregel/main.py:2675\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2666\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m loop.status == \u001b[33m\"\u001b[39m\u001b[33mout_of_steps\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2667\u001b[39m     msg = create_error_message(\n\u001b[32m   2668\u001b[39m         message=(\n\u001b[32m   2669\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRecursion limit of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[33m'\u001b[39m\u001b[33mrecursion_limit\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m reached \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2673\u001b[39m         error_code=ErrorCode.GRAPH_RECURSION_LIMIT,\n\u001b[32m   2674\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2675\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m GraphRecursionError(msg)\n\u001b[32m   2676\u001b[39m \u001b[38;5;66;03m# set final channel values as run output\u001b[39;00m\n\u001b[32m   2677\u001b[39m run_manager.on_chain_end(loop.output)\n",
      "\u001b[31mGraphRecursionError\u001b[39m: Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=37960851-a501-4637-8d3d-7df7b26fa965; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=728adc78-9001-4469-8e6b-1763291450da; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=728adc78-9001-4469-8e6b-1763291450da; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=e98adf24-5551-4a2e-9058-08371c6a8127; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=1c870514-8ae9-42bf-bdd7-60210364df70; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=9d012b48-9d8a-471e-8b87-093935f862d5; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=9d012b48-9d8a-471e-8b87-093935f862d5; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=1c870514-8ae9-42bf-bdd7-60210364df70; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=9de39574-effd-4371-a6bc-d0132fc0e153; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=8ae8e4c7-6f1d-4481-931d-652a7893e7a4; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=8ae8e4c7-6f1d-4481-931d-652a7893e7a4; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=d6ccf798-563c-465b-bf3f-7bf8d63bd445; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=d6ccf798-563c-465b-bf3f-7bf8d63bd445; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=9de39574-effd-4371-a6bc-d0132fc0e153; trace=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8,id=1bb6d9ea-b91f-49fa-90d7-52b815f97aa8\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    init_state: OrgState = {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=(\n",
    "                \"Evaluate the viability of launching an AI-enabled telehealth triage tool \"\n",
    "                \"for mid-sized US clinics.\"\n",
    "            ))\n",
    "        ],\n",
    "        \"next_agent\": None,\n",
    "        \"current_task\": \"\",\n",
    "        \"data_notes\": \"\",\n",
    "        \"market_notes\": \"\",\n",
    "        \"data_done\": False,\n",
    "        \"market_done\": False,\n",
    "        \"research_synthesis\": \"\",\n",
    "        \"research_synthesized\": False,\n",
    "        \"tech_draft\": \"\",\n",
    "        \"tech_draft_done\": False,\n",
    "        \"summary_text\": \"\",\n",
    "        \"summary_done\": False,\n",
    "        \"final_report\": \"\",\n",
    "        \"task_complete\": False,\n",
    "    }\n",
    "\n",
    "    result = graph.invoke(init_state)\n",
    "\n",
    "    print(\"\\n--- PIPELINE COMPLETE ---\\n\")\n",
    "    print((result.get(\"final_report\") or \"<no final report>\")[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bf4322",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
